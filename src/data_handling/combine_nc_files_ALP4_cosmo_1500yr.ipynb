{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e945e1-b277-4b4a-8d99-071ad793bbdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine multiple NetCDF outputs into one file\n",
    "\n",
    "To analyse multiple output `.nc` files from a simulation (open the `cases/[case_id]/archive/lnd/hist/` folder to double-check), it is recommended to concatenate these into a new single file to simplify and speed up the data analysis. For 1500 years of simulation, there are too many files to concatenate in one go. Set up three subfolders and move 500 years into each. The last 500 years of results will be used for further analysis in other notebooks. \n",
    "\n",
    "Text cells in this notebook follow Markdown syntax, while code cells are a mix of Python and bash code. We will use [cell magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to call an external command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee36221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "badd8ff0-e153-47c3-a0e7-23c54f9de824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evaler\\OneDrive - Universitetet i Oslo\\Eva\\PHD\\FATES_INCLINE\\results\\alp4-1500-cosmo\\run\\raw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Name of case folder\n",
    "case_id = \"alp4-1500-cosmo\"\n",
    "\n",
    "# Set paths to where files are stored and where to save the concatenated files.\n",
    "# one level above original output files to avoid long loading times and conflicts\n",
    "output_path_str = str(Path(f\"c:/Users/evaler/OneDrive - Universitetet i Oslo/Eva/PHD/FATES_INCLINE/results/{case_id}/run/raw\"))\n",
    "print(output_path_str)\n",
    "save_path_str = f\"c:/Users/evaler/temp/{case_id}/run\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15b824f8-c63e-430e-aac0-891ba70e1e46",
   "metadata": {},
   "source": [
    "**********************************************\n",
    "\n",
    "list the number of files in a directory with `ls -1 | wc -l`. \n",
    "\n",
    "For now, the run is not finished but I downloaded results up til 2324-07 from the run folder. To be able to compare with the warmed run (1500 years) I only want the first 1500 whole years. Manually deleting the rest for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4f001b-c6af-4005-b6c7-55cfb2bf78e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files per dir to be moved: 6000\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "num_files = 18000\n",
    "num_dest_dirs = 3\n",
    "\n",
    "# Calculate number of files to move to each directory\n",
    "files_per_dir = num_files // num_dest_dirs\n",
    "print(\"files per dir to be moved:\", files_per_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc430fc-8399-45a7-9d5a-04c58d2ee3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evaler\\OneDrive - Universitetet i Oslo\\Eva\\PHD\\FATES_INCLINE\\src\\data_handling\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f39ca7d-1f9f-4dd4-8553-adbbabf52f14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evaler\\OneDrive - Universitetet i Oslo\\Eva\\PHD\\FATES_INCLINE\\results\\alp4-1500-cosmo\\run\\raw\\1\n",
      "starting at  0\n",
      "ending at 6000\n",
      "year_month_str:  0001-01\n",
      "c:\\Users\\evaler\\OneDrive - Universitetet i Oslo\\Eva\\PHD\\FATES_INCLINE\\results\\alp4-1500-cosmo\\run\\raw\\2\n",
      "starting at  6000\n",
      "ending at 12000\n",
      "year_month_str:  0501-01\n",
      "c:\\Users\\evaler\\OneDrive - Universitetet i Oslo\\Eva\\PHD\\FATES_INCLINE\\results\\alp4-1500-cosmo\\run\\raw\\3\n",
      "starting at  12000\n",
      "ending at 18000\n",
      "year_month_str:  1001-01\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "case_long_id = \"68682ca3cc78426162f728d3bc642181_alp4-3000-cosmo-noleap\"\n",
    "\n",
    "# Move files to the new destination directories\n",
    "for i in range(num_dest_dirs):\n",
    "    src_dir = output_path_str\n",
    "    dest_dir = os.path.join(output_path_str, str(i+1))\n",
    "    print(dest_dir)\n",
    "    start_idx = i * files_per_dir\n",
    "    print(\"starting at \", start_idx)\n",
    "    end_idx = start_idx + files_per_dir\n",
    "    print(\"ending at\", end_idx)\n",
    "\n",
    "    # Move files to destination directory\n",
    "    for j in range(start_idx, end_idx):\n",
    "        year_month_str = '{:04d}-{:02d}'.format(1 + j // 12, j % 12 + 1)\n",
    "        if j == start_idx:\n",
    "            print(\"year_month_str: \", year_month_str)\n",
    "        src_file = os.path.join(src_dir, f\"{case_long_id}.clm2.h0.{year_month_str}.nc\")\n",
    "        dest_file = os.path.join(dest_dir, f\"{case_long_id}.clm2.h0.{year_month_str}.nc\")\n",
    "        shutil.move(src_file, dest_file)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43164c86-6e70-4d3a-bf9e-f460ca876702",
   "metadata": {},
   "source": [
    "Now you have specified where the files are stored, and we can combine them. The `*` in the following cell denotes a so-called wild-card, so this example will combine **all** files for history tape 0 (`h0`) contained in `cases/[case_id]/archive/lnd/hist/`. Adjust this if you want to combine outputs for a different history tape that you may have included when creating a case in the user interface. If you have several history tapes, you should repeat this whole notebook for additional tapes and give them meaningful names.\n",
    "\n",
    "Set `NC_OUT_NAME` to a descriptive name for the resulting combined single file. The given example uses the case ID and a model simulation period of 1000 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c427a02d-4ad0-4cfa-b874-d73943c03da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path_str_1 = f\"/mnt/c/Users/evaler/temp/{case_id}/run/raw/1\"\n",
    "output_path_str_2 = f\"c:/Users/evaler/temp/{case_id}/run/raw/2\"\n",
    "output_path_str_3 = f\"c:/Users/evaler/temp/{case_id}/run/raw/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00e84d9c-1cab-4450-b05b-0b4db042f61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_tape = \"h0\" # Name of the history tape to combine into a single file\n",
    "\n",
    "os.environ['NCFILES_TO_COMBINE'] = f\"*{hist_tape}*.nc\" # Name of output .nc files to combine\n",
    "os.environ['NC_OUT_NAME_1'] = f\"{case_id}.{hist_tape}.0000-0500.nc\" # Descriptive name for the resulting combined file\n",
    "os.environ['NC_OUT_NAME_2'] = f\"{case_id}.{hist_tape}.0501-1000.nc\" \n",
    "os.environ['NC_OUT_NAME_3'] = f\"{case_id}.{hist_tape}.1001-1500.nc\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101a4b0-6181-4e07-926d-dd7a9a8e37d7",
   "metadata": {},
   "source": [
    "Because of an \"Argument list too long\" error, try to remove parts of the filenames before concatenating. Remove the first 35 characters with the 'remove' function that needs to be installed first. Then list the first 10 files in the folder to check that it looks right. This needs to be done in a terminal outside the container.From the case folder:\n",
    "\n",
    "`sudo apt-get install rename`\n",
    "\n",
    "`cd archive/lnd/hist`\n",
    "\n",
    "`find . -type f -execdir rename 's/^.{35}//' {} \\;`\n",
    "\n",
    "`ls | head -10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de894198-0b31-40bd-a2e1-c972a65899df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['CASE_ID'] = case_id\n",
    "os.environ['CASE_HIST_PATH_1'] = output_path_str_1\n",
    "os.environ['CASE_HIST_PATH_2'] = output_path_str_2\n",
    "os.environ['CASE_HIST_PATH_3'] = output_path_str_3\n",
    "os.environ['SAVE_PATH'] = save_path_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ec829-8ab3-44f9-868b-7242d30e56d0",
   "metadata": {},
   "source": [
    "Use cell magic to concatenate the files with `ncrcat`. It can take some time (several minutes) if it needs to combine many files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "214c42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "$CASE_HIST_PATH_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92d4c14f-d8b1-43df-9149-7ff30b08a9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/evaler\n",
      "ncrcat: ERROR received 0 filenames; need at least two\n",
      "ncrcat Command line options cheatsheet (full details at http://nco.sf.net/nco.html#ncrcat):\n",
      "ncrcat [-3] [-4] [-5] [-6] [-7] [-A] [--bfr byt] [-C] [-c] [--cb ...] [--cnk_byt byt] [--cnk_csh byt] [--cnk_dmn nm,lmn] [--cnk_map map] [--cnk_min byt] [--cnk_plc plc] [--cnk_scl sz] [-D dbg_lvl] [-d ...] [-F] [--fl_fmt fmt] [-G grp:lvl] [-g ...] [--glb ...] [-H] [-h] [--hdr_pad nbr] [--hpss] [-L lvl] [-l path] [--md5_dgs] [--msa] [-n ...] [--no_cll_msr] [--no_frm_trm] [--no_tmp_fl] [-O] [-o out.nc] [-p path] [--ppc ...] [-R] [-r] [--ram_all] [--rec_apn] [-t thr_nbr] [--uio] [--unn] [-v ...] [-X box] [-x] in.nc [...] [out.nc]\n",
      "\n",
      "-3, --3, classic\tOutput file in netCDF3 CLASSIC (32-bit offset) storage format\n",
      "-4, --4, netcdf4\tOutput file in netCDF4 (HDF5) storage format\n",
      "-5, --5, 64bit_data\tOutput file in netCDF3 64-bit data (i.e., CDF5, PnetCDF) storage format\n",
      "-6, --6, 64, 64bit_offset\tOutput file in netCDF3 64-bit offset storage format\n",
      "-7, --7, netcdf4_classic\tOutput file in netCDF4 CLASSIC format (3+4=7)\n",
      "-A, --apn, append\tAppend to existing output file, if any\n",
      "    --bfr_sz, buffer_size sz\tBuffer size to open files with\n",
      "-C, --no_crd, xcl_ass_var\tExclude coordinates, CF-associated variables (ancillary, bounds, ...)\n",
      "-c, --crd, xtr_ass_var\tExtract coordinates, CF-associated variables (ancillary, bounds, ...)\n",
      "    --cb, clm_bnd\tCF Climatology and bounds information as yr_srt,yr_end,mth_srt,mth_end,tpd\n",
      "    --cnk_byt, chunk_byte sz_byt\tChunksize in bytes\n",
      "    --cnk_csh, chunk_cache sz_byt\tChunk cache size in bytes\n",
      "    --cnk_dmn, chunk_dimension nm,sz_lmn\tChunksize of dimension nm (in elements not bytes)\n",
      "    --cnk_map, chunk_map map\tChunking map [dmn,lfp,nc4,nco,prd,rd1,rew,scl,xpl,xst]\n",
      "    --cnk_min, chunk_min sz_byt\tMinimum size [B] of variable to chunk\n",
      "    --cnk_plc, chunk_policy plc\tChunking policy [all,g2d,g3d,xpl,xst,uck]\n",
      "    --cnk_scl, chunk_scalar sz_lmn\tChunksize scalar (in elements not bytes) (for all dimensions)\n",
      "-D, --dbg_lvl, debug-level lvl\tDebug-level is lvl\n",
      "-d, --dmn, dimension dim,[min][,[max][[[,stride[,subcycle[,interleave]]]]]] Dimension's limits, stride, subcycle, interleave in hyperslab\n",
      "-F, --ftn, fortran\tFortran indexing conventions (1-based) for I/O\n",
      "    --fl_fmt, file_format fmt\tFile format for output [classic,64bit_offset,64bit_data,netcdf4,netcdf4_classic]\n",
      "-G, --gpe [grp_nm][:[lvl]]\tGroup Path Editing path, levels to replace\n",
      "-g, --grp grp1[,grp2[...]] Group(s) to process (regular expressions supported)\n",
      "    --glb_att_add nm=val\tGlobal attribute to add\n",
      "-H, --fl_lst_in, file_list\tDo not create \"input_file_list\" global attribute\n",
      "-h, --hst, history\tDo not append to \"history\" global attribute\n",
      "    --hdr_pad, header_pad\tPad output header with nbr bytes\n",
      "    --hpss, hpss_try\tSearch for unfound files on HPSS with 'hsi get ...'\n",
      "-L, --dfl_lvl, deflate lvl\tLempel-Ziv deflation/compression (lvl=0..9) for netCDF4 output\n",
      "-l, --lcl, local path\tLocal storage path for remotely-retrieved files\n",
      "    --md5_dgs, md5_digest\tPerform MD5 digests\n",
      "    --msa, msa_usr_rdr\tMulti-Slab-Algorithm output in User-Order\n",
      "-n, --nintap nbr_files,[nbr_numeric_chars[,increment]] NINTAP-style abbreviation of file list\n",
      "    --no_cll_msr\tDo not extract cell_measures variables\n",
      "    --no_frm_trm\tDo not extract formula_terms variables\n",
      "    --no_tmp_fl\t\tDo not write output to temporary file\n",
      "-O, --ovr, overwrite\tOverwrite existing output file, if any\n",
      "-o, --output, fl_out \tOutput file name (or use last positional argument)\n",
      "-p, --pth, path path\tPath prefix for all input filenames\n",
      "    --ppc v1[,v2[,...]]=prc\tPrecision-Preserving Compression: Number of total or decimal significant digits\n",
      "-R, --rtn, retain\tRetain remotely-retrieved files after use\n",
      "-r, --revision, version\tCompile-time configuration and/or program version\n",
      "    --ram_all, diskless_all\tOpen netCDF3 files and create output files in RAM\n",
      "    --rec_apn, record_append\tAppend records directly to output file\n",
      "-t, --thr_nbr, threads, omp_num_threads thr_nbr\tThread number for OpenMP\n",
      "    --uio, --share_all\tUnbuffered I/O to read/write netCDF3 file(s)\n",
      "    --unn, union\tSelect union of specified groups and variables\n",
      "-v, --variable var1[,var2[...]] Variable(s) to process (regular expressions supported)\n",
      "-X, --auxiliary lon_min,lon_max,lat_min,lat_max\tAuxiliary coordinate bounding box\n",
      "-x, --xcl, exclude\tExtract all variables EXCEPT those specified with -v\n",
      "in.nc [...]\t\tInput file names\n",
      "\t\t\tOutput file name (or use -o switch)\n",
      "\n",
      "Eight ways to find more help on ncrcat and/or NCO:\n",
      "1. Examples:     http://nco.sf.net/nco.html#xmp_ncrcat\n",
      "2. Ref. manual:  http://nco.sf.net/nco.html#ncrcat\n",
      "3. User Guide:   http://nco.sf.net#RTFM\n",
      "4. Manual pages: 'man ncrcat', 'man nco', ...\n",
      "5. Homepage:     http://nco.sf.net\n",
      "6. Code:         http://github.com/nco/nco\n",
      "7. Help Forum:   http://sf.net/p/nco/discussion/9830\n",
      "8. Publications: http://nco.sf.net#pub\n",
      "Post questions, suggestions, patches at http://sf.net/projects/nco\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'cd ~\\npwd\\nncrcat $CASE_HIST_PATH_1$NCFILES_TO_COMBINE $SAVE_PATH$NC_OUT_NAME_1\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mbash\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcd ~\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mpwd\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mncrcat $CASE_HIST_PATH_1$NCFILES_TO_COMBINE $SAVE_PATH$NC_OUT_NAME_1\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\evaler\\.conda\\envs\\vscode\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2430\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2428\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2429\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2430\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2432\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2434\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\evaler\\.conda\\envs\\vscode\\lib\\site-packages\\IPython\\core\\magics\\script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[1;34m(line, cell)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     line \u001b[39m=\u001b[39m script\n\u001b[1;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshebang(line, cell)\n",
      "File \u001b[1;32mc:\\Users\\evaler\\.conda\\envs\\vscode\\lib\\site-packages\\IPython\\core\\magics\\script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mraise_error \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    301\u001b[0m     \u001b[39m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     rc \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mreturncode \u001b[39mor\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'b'cd ~\\npwd\\nncrcat $CASE_HIST_PATH_1$NCFILES_TO_COMBINE $SAVE_PATH$NC_OUT_NAME_1\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ~\n",
    "pwd\n",
    "ncrcat $CASE_HIST_PATH_1$NCFILES_TO_COMBINE $SAVE_PATH$NC_OUT_NAME_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef269d8-f7ee-4e7a-a35a-d7b5dde08e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ncrcat $PWD/..$CASE_HIST_PATH_2$NCFILES_TO_COMBINE $HOME$SAVE_PATH$NC_OUT_NAME_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e21e7e-a68f-4ec8-a759-9c0a73bcd5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ncrcat $PWD/..$CASE_HIST_PATH_3$NCFILES_TO_COMBINE $HOME$SAVE_PATH$NC_OUT_NAME_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "98bd30b8b4c3c7b34184719ef7bcbbe0e9ad7d5e716650527163f9a187dd92d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
